import pytest
import json
import asyncio
from unittest.mock import MagicMock, patch
from a2a.server.agent_execution.context import RequestContext
from a2a.server.events.event_queue import EventQueue
from a2a.types import Message, Role, TextPart, MessageSendParams
from agents.training_planning_agent import TrainingPlanningExecutor
from agents.training_executor import StrategyType
from utils.a2a_bridge import create_text_message

# Mock Response object for httpx
class MockResponse:
    def __init__(self, json_data, status_code=200):
        self.json_data = json_data
        self.status_code = status_code

    def json(self):
        return self.json_data

    def raise_for_status(self):
        if self.status_code != 200:
            raise Exception(f"HTTP Error: {self.status_code}")

@pytest.mark.asyncio
class TestStrategyTriggering:

    async def run_planner_with_mock(self, report_text, expected_strategy_response):
        """
        Helper to run the planner with a specific input report and a mocked LLM response.
        """
        # 1. Setup Input
        input_payload = json.dumps({
            "analysis_report": report_text,
            "user_goal": "Optimize for this scenario"
        })
        
        # Use helper to create message, ensuring correct structure
        message = create_text_message(input_payload, role=Role.user)
        
        # Correctly wrap message in MessageSendParams for RequestContext
        params = MessageSendParams(message=message)
        context = RequestContext(request=params)
        event_queue = EventQueue()

        # 2. Mock httpx.AsyncClient
        llm_generated_content = json.dumps(expected_strategy_response)
        mock_llm_response_body = {"text": llm_generated_content}
        
        mock_response = MockResponse(mock_llm_response_body)

        with patch("httpx.AsyncClient.post", return_value=mock_response) as mock_post:
            executor = TrainingPlanningExecutor()
            await executor.execute(context, event_queue)

        # 3. Validation
        # Use dequeue_event since EventQueue.events is not exposed and it's an async queue
        assert not event_queue.queue.empty(), "No event generated by executor"
        
        result_msg = await event_queue.dequeue_event(no_wait=True)
        
        # Robustly extract text based on SDK version ambiguity
        result_text = ""
        if result_msg.parts:
            part = result_msg.parts[0]
            # Try main.py style access first
            if hasattr(part, "root") and hasattr(part.root, "text"):
                result_text = part.root.text
            # Try a2a_bridge style access (if TextPart has .text)
            elif hasattr(part, "text"):
                result_text = part.text
            else:
                 pytest.fail(f"Unknown part structure: {part}")
        
        try:
            plan = json.loads(result_text)
        except json.JSONDecodeError:
            pytest.fail(f"Executor produced invalid JSON: {result_text}")

        return plan

    async def test_full_training_trigger(self):
        report = (
            "The dataset is large (50GB) and covers a completely new domain not seen in pre-training. "
            "We have high computational resources (8x A100s) and require maximum accuracy. "
            "Data diversity is high."
        )
        expected_llm_decision = {"strategy": "full_training"}
        
        plan = await self.run_planner_with_mock(report, expected_llm_decision)
        
        assert plan["strategy"] == "full_training"
        assert "epochs" in plan
        assert "learning_rate" in plan

    async def test_lora_trigger(self):
        report = (
            "The dataset is small (100MB) and specific to a niche task. "
            "We have limited compute (single T4 GPU). "
            "We need to adapt a generic model efficiently."
        )
        expected_llm_decision = {"strategy": "lora"}
        
        plan = await self.run_planner_with_mock(report, expected_llm_decision)
        
        assert plan["strategy"] == "lora"
        assert "lora_r" in plan
        assert plan["lora_r"] == 8  # Check default

    async def test_layer_freezing_trigger(self):
        report = (
            "We need a balance between speed and accuracy. "
            "The lower level features of the pre-trained model are likely relevant, "
            "so we only want to update the higher semantic layers to save time."
        )
        expected_llm_decision = {"strategy": "layer_freezing"}
        
        plan = await self.run_planner_with_mock(report, expected_llm_decision)
        
        assert plan["strategy"] == "layer_freezing"
        assert "freeze_layers" in plan

    async def test_transfer_learning_trigger(self):
        report = (
            "We want to leverage knowledge from a similar domain. "
            "Standard transfer learning approach is sufficient. "
            "We have a moderate sized dataset."
        )
        expected_llm_decision = {"strategy": "transfer"}
        
        plan = await self.run_planner_with_mock(report, expected_llm_decision)
        
        assert plan["strategy"] == "transfer"

    async def test_continual_learning_trigger(self):
        report = (
            "We have a stream of datasets arriving sequentially. "
            "Ideally, the model should learn Task A, then Task B, without forgetting Task A. "
            "We have a list of task datasets."
        )
        expected_llm_decision = {"strategy": "continual"}
        
        plan = await self.run_planner_with_mock(report, expected_llm_decision)
        
        assert plan["strategy"] == "continual"

    async def test_curriculum_learning_trigger(self):
        report = (
            "The data contains samples of varying difficulty. "
            "It is beneficial to present easier samples first during training "
            "to stabilize convergence before introducing harder samples."
        )
        expected_llm_decision = {"strategy": "curriculum"}
        
        plan = await self.run_planner_with_mock(report, expected_llm_decision)
        
        assert plan["strategy"] == "curriculum"
